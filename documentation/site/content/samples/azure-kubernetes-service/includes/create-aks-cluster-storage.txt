#### Create storage

Our usage pattern for the operator involves creating Kubernetes "persistent volumes" to allow the WebLogic Server to persist its configuration and data separately from the Kubernetes Pods that run WebLogic Server workloads.

You will create an external data volume to access and persist data. There are several options for data sharing as described in [Storage options for applications in Azure Kubernetes Service (AKS)](https://docs.microsoft.com/azure/aks/concepts-storage).

You will dynamically create and use a persistent volume with Azure Files NFS share.  For details about this full featured cloud storage solution, see the [Azure Files Documentation](https://docs.microsoft.com/azure/aks/azure-files-dynamic-pv).

##### Create an Azure Storage account and NFS share

1. Create an Azure Storage Account.

    Create a storage account using the Azure CLI. Make sure the following values are specified:

    | Option name | Value | Notes |
    |-------------------|---------------|-------|
    | `name` | `$AKS_PERS_STORAGE_ACCOUNT_NAME` | The storage account name can contain only lowercase letters and numbers, and must be between 3 and 24 characters in length. |
    | `sku`  | `Premium_LRS` | Only `Premium_LRS` and `Premium_ZRS` work for NFS share, see the [Azure Files NFS Share Documentation](https://docs.microsoft.com/azure/storage/files/storage-files-how-to-create-nfs-shares?tabs=azure-portal#applies-to).|
    | `https-only` | `false` | You can't mount an NFS file share unless you disable secure transfer. |
    | `default-action` | `Deny` | For security, we suggest that you deny access by default and choose to allow access from the AKS cluster network. |

    ```shell

    $ az storage account create \
        --resource-group $AKS_PERS_RESOURCE_GROUP \
        --name $AKS_PERS_STORAGE_ACCOUNT_NAME \
        --location $AKS_PERS_LOCATION \
        --sku Premium_LRS \
        --kind FileStorage \
        --https-only false \
        --default-action Deny
    ```

    Successful output will be a JSON object with the entry `"type": "Microsoft.Storage/storageAccounts"`.

2. Create an NFS share.

    We strongly recommend NFS instead of SMB. NFS evolved from the UNIX operating system, and other variants such as GNU/Linux. For this reason, when using NFS with container technologies such as Docker, it is less likely to have problems for concurrent reads and file locking.

    Please be sure to enable NFS v4.1. Versions lower than v4.1 will have problems.

    To create the file share, you must use `NoRootSquash` to allow the operator to change the ownership of the directory in the NFS share.

    Otherwise, you will get an error like `chown: changing ownership of '/shared': Operation not permitted`.

    The following command creates an NFS share with 100GiB:

    ```shell
    
    # Create NFS file share
    $ az storage share-rm create \
        --resource-group $AKS_PERS_RESOURCE_GROUP \
        --storage-account $AKS_PERS_STORAGE_ACCOUNT_NAME \
        --name ${AKS_PERS_SHARE_NAME} \
        --enabled-protocol NFS \
        --root-squash NoRootSquash \
        --quota 100
    ```

    The command provisions an NFS file share with NFS 4.1 or above.

3. Assign the AKS cluster **Contributor** role to access the storage account.

    You must configure role assignment allowing access from the AKS cluster to the storage account.

    Get the `objectId` of the AKS cluster with the following command and save it with the variable `AKS_OBJECT_ID`:

    ```shell
    $ AKS_OBJECT_ID=$(az aks show --name ${AKS_CLUSTER_NAME} --resource-group ${AKS_PERS_RESOURCE_GROUP} --query "identity.principalId" -o tsv)
    ```

    Get the Id of the storage account with the following command:

    ```shell
    $ STORAGE_ACCOUNT_ID=$(az storage account show --name ${AKS_PERS_STORAGE_ACCOUNT_NAME} --resource-group ${AKS_PERS_RESOURCE_GROUP} --query "id" -o tsv)
    ```

    Now, you are able to create a role assignment to grant the AKS cluster the **Contributor** role in the scope of the storage account. Then, the AKS cluster is able to access the file share.

    ```shell
    $ az role assignment create \
      --assignee-object-id "${AKS_OBJECT_ID}" \
      --assignee-principal-type "ServicePrincipal" \
      --role "Contributor" \
      --scope "${STORAGE_ACCOUNT_ID}"
    ```

    Successful output will be a JSON object like the following:

    ```json
    {
    "condition": null,
    "conditionVersion": null,
    "createdBy": "d6fe7d09-3330-45b6-ae32-4dd5e3310835",
    "createdOn": "2023-05-11T04:13:04.922943+00:00",
    "delegatedManagedIdentityResourceId": null,
    "description": null,
    "id": "/subscriptions/xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx/resourceGroups/wlsresourcegroup1683777168/providers/Microsoft.Storage/storageAccounts/wlsstorage1683777168/providers/Microsoft.Authorization/roleAssignments/93dae12d-21c8-4844-99cd-e8b088356af6",
    "name": "93dae12d-21c8-4844-99cd-e8b088356af6",
    "principalId": "95202c6f-2073-403c-b9a7-7d2f1cbb4541",
    "principalName": "3640cbf2-4db7-43b8-bcf6-1e51d3e90478",
    "principalType": "ServicePrincipal",
    "resourceGroup": "wlsresourcegroup1683777168",
    "roleDefinitionId": "/subscriptions/xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx/providers/Microsoft.Authorization/roleDefinitions/b24988ac-6180-42a0-ab88-20f7382dd24c",
    "roleDefinitionName": "Contributor",
    "scope": "/subscriptions/xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx/resourceGroups/wlsresourcegroup1683777168/providers/Microsoft.Storage/storageAccounts/wlsstorage1683777168",
    "type": "Microsoft.Authorization/roleAssignments",
    "updatedBy": "d6fe7d09-3330-45b6-ae32-4dd5e3310835",
    "updatedOn": "2023-05-11T04:13:04.922943+00:00"
   }
   ```

4. Configure network security.

    You must configure network security allowing access from the AKS cluster to the file share.

    First, you must get the virtual network name and the subnet name of the AKS cluster.

    Run the following commands to get network information:

    ```shell
    # get the resource group name of the AKS managed resources
    $ aksMCRGName=$(az aks show --name $AKS_CLUSTER_NAME --resource-group $AKS_PERS_RESOURCE_GROUP -o tsv --query "nodeResourceGroup")
    $ echo ${aksMCRGName}

    # get network name of AKS cluster
    $ aksNetworkName=$(az graph query -q "Resources \
        | where type =~ 'Microsoft.Network/virtualNetworks' \
        | where resourceGroup  =~ '${aksMCRGName}' \
        | project name = name" --query "data[0].name"  -o tsv)
    $ echo ${aksNetworkName}

    # get subnet name of AKS agent pool
    $ aksSubnetName=$(az network vnet subnet list --resource-group ${aksMCRGName} --vnet-name ${aksNetworkName} -o tsv --query "[*].name")
    $ echo ${aksSubnetName}

    # get subnet id of the AKS agent pool
    $ aksSubnetId=$(az network vnet subnet list --resource-group ${aksMCRGName} --vnet-name ${aksNetworkName} -o tsv --query "[*].id")
    $ echo ${aksSubnetId}
    ```

    You must enable the service endpoint `Microsoft.Storage` for the subnet using the following command:

    ```shell
    $ az network vnet subnet update \
        --resource-group $aksMCRGName \
        --name ${aksSubnetName} \
        --vnet-name ${aksNetworkName} \
        --service-endpoints Microsoft.Storage
    ```

    It takes several minutes to enable the service endpoint; successful output will be a JSON object like the following:

    ```text
    "serviceEndpoints": [
    {
      "locations": [
        "eastus",
        "westus"
      ],
      "provisioningState": "Succeeded",
      "service": "Microsoft.Storage"
    }
    ```

    Now you must create a network rule to allow access from the AKS cluster.
    The following command enables access from the AKS subnet to the storage account:

    ```shell
    $ az storage account network-rule add \
      --resource-group $AKS_PERS_RESOURCE_GROUP \
      --account-name $AKS_PERS_STORAGE_ACCOUNT_NAME \
      --subnet ${aksSubnetId}
    ```

    Successful output will be a JSON object with a virtual network rule like:

    ```text
    "virtualNetworkRules": [
      {
        "action": "Allow",
        "state": "Succeeded",
        "virtualNetworkResourceId": "${aksSubnetId}"
      }
    ]
    ```

##### Create SC and PVC

##### Generated configuration files
Use the following command to generate configuration files.

```shell
cat >azure-csi-nfs-${TIMESTAMP}.yaml <<EOF
# Copyright (c) 2018, 2023, Oracle and/or its affiliates.
# Licensed under the Universal Permissive License v 1.0 as shown at https://oss.oracle.com/licenses/upl.

apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: azurefile-csi-nfs
provisioner: file.csi.azure.com
parameters:
  protocol: nfs
  resourceGroup: ${AKS_PERS_RESOURCE_GROUP}
  storageAccount: ${AKS_PERS_STORAGE_ACCOUNT_NAME}
  shareName: ${AKS_PERS_SHARE_NAME}
reclaimPolicy: Delete
volumeBindingMode: Immediate
allowVolumeExpansion: true

EOF

cat >pvc-${TIMESTAMP}.yaml <<EOF
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: wls-azurefile-${TIMESTAMP}
spec:
  accessModes:
    - ReadWriteMany
  storageClassName: azurefile-csi-nfs
  resources:
    requests:
      storage: 5Gi

EOF
```

Use the `kubectl` command to create the Storage Class and persistent volume claim in the `default` namespace.

```shell
$ kubectl apply -f azure-csi-nfs-${TIMESTAMP}.yaml
$ kubectl apply -f pvc-${TIMESTAMP}.yaml
```

Use the following command to verify:

```shell
$ kubectl get sc
```

Example of `kubectl get sc` output:

```shell
$ kubectl get sc
NAME                    PROVISIONER          RECLAIMPOLICY   VOLUMEBINDINGMODE      ALLOWVOLUMEEXPANSION   AGE
azurefile               file.csi.azure.com   Delete          Immediate              true                   30m
azurefile-csi           file.csi.azure.com   Delete          Immediate              true                   30m
azurefile-csi-nfs       file.csi.azure.com   Delete          Immediate              true                   24m
azurefile-csi-premium   file.csi.azure.com   Delete          Immediate              true                   30m
azurefile-premium       file.csi.azure.com   Delete          Immediate              true                   30m
...
```

```shell
$ kubectl get pvc
```

Example of `kubectl get pvc` output:

```shell
$ kubectl get pvc
NAME                       STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS        AGE
wls-azurefile-1693900684   Bound    pvc-1f615766-0f21-4c88-80e1-93c9bdabb3eb   5Gi        RWX            azurefile-csi-nfs   46s
```
