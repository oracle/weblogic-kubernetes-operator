# Copyright 2017, 2019, Oracle Corporation and/or its affiliates.  All rights reserved.
# Licensed under the Universal Permissive License v 1.0 as shown at http://oss.oracle.com/licenses/upl.

#
#  Wercker build file for Oracle WebLogic Server Kubernetes Operator
#

#
#  Wercker application is at : https://app.wercker.com/Oracle/weblogic-kubernetes-operator
#
#  Werkcer workflow looks like this:
#
#  build -> integration-tests (1.7.9)
#        -> integration-tests (1.8.5)
#        -> quality
#

box:
  id: store/oracle/serverjre
  username: $DOCKER_USERNAME
  password: $DOCKER_PASSWORD
  tag: 8

# This is the main build pipeline that builds the codebase and runs unit tests.
build:
  steps:
  - script:
    name: Hello
    code: |
      echo "Building Oracle WebLogic Server Kubernetes Operator..."
      echo "The branch and commit id are $WERCKER_GIT_BRANCH, $WERCKER_GIT_COMMIT"
      export JAR_VERSION="`grep -m1 "<version>" pom.xml | cut -f2 -d">" | cut -f1 -d "<"`"
      export IMAGE_TAG_OPERATOR="${WERCKER_GIT_BRANCH//[_\/]/-}"
  - script:
    name: Install pre-reqs
    code: |
      yum -y install tar gzip procps
  - script:
    name: Install helm
    code: |
      #!/bin/bash
      echo @@ "Helm installation starts"
      export HELM_VERSION=${HELM_VERSION:-v2.11.0}
      curl -LO http://kubernetes-helm.storage.googleapis.com/helm-${HELM_VERSION}-linux-amd64.tar.gz
      mkdir /tmp/helm
      tar xzf helm-${HELM_VERSION}-linux-amd64.tar.gz -C /tmp/helm
      chmod +x /tmp/helm/linux-amd64/helm
      mv /tmp/helm/linux-amd64/helm /usr/local/bin/
      rm -rf /tmp/helm
      helm version
      echo @@ "Helm is installed."
  - wercker/maven:
    goals: clean install
    version: 3.5.2
    profiles: helm-installation-test
    cache_repo: true
  - internal/docker-build:
    dockerfile: Dockerfile
    image-name: $REPO_REPOSITORY:$IMAGE_TAG_OPERATOR
    no-cache: true
    build-args: VERSION=$JAR_VERSION
    registry-auth-config: |
      {
        "https://index.docker.io/v1/": {
          "username": "${DOCKER_USERNAME}",
          "password": "${DOCKER_PASSWORD}"
        }
      }
  # push the image to Docker using the GIT branch as the tag
  # this image needs to be available to the integration-test pipeline for testing
  - internal/docker-push:
    image-name: $REPO_REPOSITORY:$IMAGE_TAG_OPERATOR
    username: $REPO_USERNAME
    password: $REPO_PASSWORD
    repository: $REPO_REPOSITORY
    registry: $REPO_REGISTRY
    tag: $IMAGE_TAG_OPERATOR

# This pipeline runs integration tests against a K8s cluster on OCI.
command-timeout: 60
integration-test-java:
  steps:
  - script:
    name: obtain lease on k8s cluster
    code: |
      #!/bin/bash

      cp /etc/hosts $WERCKER_PIPELINE_DIR/hosts
      sed -i "$ a ${OCI_K8S_WORKER0_IP} ${OCI_K8S_WORKER0_HOSTNAME}" $WERCKER_PIPELINE_DIR/hosts
      cp $WERCKER_PIPELINE_DIR/hosts /etc/hosts

      # Update KUBECONFIG for K8S cluster
      export K8S_NODEPORT_HOST="${OCI_K8S_WORKER0_HOSTNAME}"
      sed -i -e "s,%ADDRESS%,https://$OCI_K8S_MASTER_IP:443,g" $WERCKER_SOURCE_DIR/build/kube.config
      sed -i -e "s,%CLIENT_CERT_DATA%,$OCI_K8S_CLIENT_CERT_DATA,g" $WERCKER_SOURCE_DIR/build/kube.config
      sed -i -e "s,%CLIENT_KEY_DATA%,$OCI_K8S_CLIENT_KEY_DATA,g" $WERCKER_SOURCE_DIR/build/kube.config
      export KUBECONFIG="$WERCKER_SOURCE_DIR/build/kube.config"

      # running on Wercker
      export WERCKER="true"

      # install kubectl
      # export K8S_CLIENT_VERSION="$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)"   #latest version
      export K8S_CLIENT_VERSION=${K8S_CLIENT_VERSION:-v1.10.5}
      curl -LO https://storage.googleapis.com/kubernetes-release/release/${K8S_CLIENT_VERSION}/bin/linux/amd64/kubectl
      chmod +x ./kubectl
      mv ./kubectl /usr/local/bin/kubectl

      # install maven, includes java as dependency
      curl -LO http://repos.fedorapeople.org/repos/dchen/apache-maven/epel-apache-maven.repo
      mv epel-apache-maven.repo /etc/yum.repos.d/
      yum install -y apache-maven
      export M2_HOME="/usr/share/apache-maven"
      export PATH=$M2_HOME/bin:$PATH:$JAVA_HOME/bin

      # install opensll
      yum install -y openssl

      echo @@ "Calling 'kubectl version'"
      kubectl version
      
      echo @@ "Helm installation starts"
      export HELM_VERSION=${HELM_VERSION:-v2.11.0}
      curl -LO http://kubernetes-helm.storage.googleapis.com/helm-${HELM_VERSION}-linux-amd64.tar.gz
      mkdir /tmp/helm
      tar xzf helm-${HELM_VERSION}-linux-amd64.tar.gz -C /tmp/helm
      chmod +x /tmp/helm/linux-amd64/helm
      mv /tmp/helm/linux-amd64/helm /usr/local/bin/
      rm -rf /tmp/helm
      helm version
      echo @@ "Helm is installed."

      # obtain an exclusive k8s cluster lease using the 'lease.sh' helper script
      #   - first set LEASE_ID to a unique value
      #   - then try obtain the lease, block up to 100 minutes (wercker pipeline should timeout before then)
      export LEASE_ID="${WERCKER_STEP_ID}-pid$$"
      echo @@
      echo @@ "Obtaining lease!"
      echo @@
      echo @@ "About to block up to the 100 minutes trying to get exclusive access to the kubernetes cluster."
      echo @@ "If this blocks unexpectedly and you are sure that the kubernetes cluster isn't in use by "
      echo @@ "another Wercker pipeline, you can force the lease to free up via 'kubectl delete cm acceptance-test-lease'."
      echo @@ "LEASE_ID=$LEASE_ID host=$HOST date=`date` user=$USER."
      echo @@
      echo @@ "Current lease owner (if any):"
      $WERCKER_SOURCE_DIR/src/integration-tests/bash/lease.sh -s
      echo @@
      echo @@ "About to try obtain lease:"
      $WERCKER_SOURCE_DIR/src/integration-tests/bash/lease.sh -o "$LEASE_ID" -t $((100 * 60))
      echo @@

      export HOST_PATH="/scratch"
      export PV_ROOT=$HOST_PATH
      export RESULT_ROOT="$WERCKER_OUTPUT_DIR/k8s_dir"
      mkdir -m 777 -p $RESULT_ROOT
      export PROJECT_ROOT="${WERCKER_SOURCE_DIR}"

      export IMAGE_NAME_OPERATOR="${REPO_REPOSITORY}"
      export IMAGE_TAG_OPERATOR="${WERCKER_GIT_BRANCH//[_\/]/-}"
      export IMAGE_PULL_POLICY_OPERATOR="Always"
      export IMAGE_PULL_SECRET_OPERATOR="ocir-operator"
      export IMAGE_NAME_WEBLOGIC="${IMAGE_NAME_WEBLOGIC:-$REPO_PREFIX/weblogic}"
      export IMAGE_TAG_WEBLOGIC="${IMAGE_TAG_WEBLOGIC:-19.1.0.0}"
      export IMAGE_PULL_SECRET_WEBLOGIC="ocir-weblogic"

      # If cleanup fails, it releases the lease, and the step needs to fail.
      # $WERCKER_SOURCE_DIR/integration-tests/src/test/resources/setupenv.sh
      $WERCKER_SOURCE_DIR/src/integration-tests/bash/cleanup.sh || exit 1

      echo "Integration test suite running for test image: $IMAGE_NAME_OPERATOR:$IMAGE_TAG_OPERATOR"
      echo "WebLogic version is: $IMAGE_NAME_WEBLOGIC:$IMAGE_TAG_WEBLOGIC"

      # Echo the image's WL version - we don't care if this fails...
      $WERCKER_SOURCE_DIR/src/integration-tests/introspector/util_krun.sh -t 120 -i $IMAGE_NAME_WEBLOGIC:$IMAGE_TAG_WEBLOGIC -s $IMAGE_PULL_SECRET_WEBLOGIC -c 'source /u01/oracle/wlserver/server/bin/setWLSEnv.sh && java weblogic.version'

  - script:
    name: Install pre-reqs
    code: |
      yum -y install tar gzip procps

  - wercker/maven:
    goals: clean verify
    version: 3.5.2
    profiles: java-integration-tests
    
  after-steps:
  - script:
    name: cleanup and store
    code: |
      #!/bin/bash
      function cleanup_and_store {
      
        # $WERCKER_SOURCE_DIR/integration-tests/src/test/resources/statedump.sh
        
        # clean up
        yum clean all

        # store the artifacts so we can download them easily
        tar czvf ${WERCKER_REPORT_ARTIFACTS_DIR}/integration-test-data.tar.gz /pipeline/output/*
      }

      cleanup_and_store

# This pipeline runs quality checks
quality:
  steps:
  - script:
    name: Install pre-reqs
    code: |
      yum -y install tar gzip procps
  - script:
    name: Install helm
    code: |
      #!/bin/bash
      echo @@ "Helm installation starts"
      export HELM_VERSION=${HELM_VERSION:-v2.11.0}
      curl -LO http://kubernetes-helm.storage.googleapis.com/helm-${HELM_VERSION}-linux-amd64.tar.gz
      mkdir /tmp/helm
      tar xzf helm-${HELM_VERSION}-linux-amd64.tar.gz -C /tmp/helm
      chmod +x /tmp/helm/linux-amd64/helm
      mv /tmp/helm/linux-amd64/helm /usr/local/bin/
      rm -rf /tmp/helm
      helm version
      echo @@ "Helm is installed."
  - wercker/maven:
    profiles: build-sonar
    maven_opts: -Dsonar.login=${SONAR_LOGIN} -Dsonar.password=${SONAR_PASSWORD} -Dsonar.host.url=${SONAR_HOST}
    goals: clean install sonar:sonar
    cache_repo: true
    version: 3.5.2

promote-image:
  steps:
  - internal/docker-push:
    image-name: $REPO_REPOSITORY:$IMAGE_TAG_OPERATOR
    username: $DOCKER_USERNAME
    password: $DOCKER_PASSWORD
    repository: oracle/weblogic-kubernetes-operator
    tag: $IMAGE_TAG_OPERATOR
    build-args: VERSION=$VERSION

dev:
  steps:
  - internal/shell
